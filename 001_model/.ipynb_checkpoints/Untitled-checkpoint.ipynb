{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3253d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from Feature_Engineering_v2 import Ordinal_Transformer_lob, Feq_Transformer_Multi, Dummy_Transformer, Pair_Transformer\n",
    "# from Feature_Generation_v2 import Location_Transformer, Group_Transformer, Individual_Behavior_Transformer, Time_Difference_Transformer, USD_Transform_ordinal\n",
    "# from Model_Visualization_Toolbox_v3 import Threshold_visual, performance_visual, Feature_Importance_Plot_XGB, Feature_Importance_Plot_LG, Feature_Importance_Plot_RF_ADA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a Transformer\n",
    "class Frequency_Transformer_Single():\n",
    "    \n",
    "    def __init__(self, name_f, name_Label):\n",
    "        self.name_f = name_f\n",
    "        self.Label = name_Label\n",
    "        self.nf_name = name_f + \"_ave\"\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.group = X.groupby(by = self.name_f)[self.Label].mean()\n",
    "        self.med = np.nanmean(self.group.values)\n",
    " \n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        X[self.nf_name] = X[self.name_f].map(self.group)\n",
    "        if X[self.nf_name].isna().sum()==0:\n",
    "            return X\n",
    "        else:\n",
    "            if X[self.name_f].dtype=='float64':\n",
    "                return self.numeric_fill(X, y)\n",
    "            else:\n",
    "                X[self.nf_name].fillna(self.med, inplace=True)\n",
    "                return X\n",
    "               \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def numeric_fill(self, X, y=None):\n",
    "        nan_indices = X[self.nf_name].isna()\n",
    "        values_in_feature2 = X.loc[nan_indices, self.name_f]\n",
    "        list_a=[]\n",
    "        num = 10\n",
    "        for x in values_in_feature2.values:\n",
    "            list_a.append(self.find_near(x,num))\n",
    "        \n",
    "        X[self.nf_name][nan_indices]=list_a\n",
    "        return X\n",
    "        \n",
    "    def find_near(self, x, num):\n",
    "        A_group = np.array(self.group.index)\n",
    "        diff = np.abs(A_group-x)\n",
    "        indices = np.argpartition(diff,num)[:num]\n",
    "        nearest_values=A_group[indices]\n",
    "        x = self.group[nearest_values].sum()/num\n",
    "        return x\n",
    "        \n",
    "#load the original data\n",
    "df = pd.read_csv(\"fraud_payment_data.csv\")\n",
    "\n",
    "#Feature engineering\n",
    "df['Time_step']=pd.to_datetime(df.Time_step)\n",
    "df['dayofyear'] = df.Time_step.dt.dayofyear\n",
    "df['SDAYPair']=df['Sender_Id'] + '-' + df['dayofyear'].astype('str')\n",
    "\n",
    "#Define key features for model training after EDA\n",
    "features = ['SDAYPair_ave', 'USD_amount_ave', 'Sender_Sector_ave', 'Bene_Account_ave']\n",
    "target = 'Label'\n",
    "\n",
    "#Train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42) \n",
    "X_train_raw, y_train = train, train[target]\n",
    "X_test_raw,  y_test  = test, test[target]\n",
    "\n",
    "feature_pipeline = Pipeline([('fq_sday', Frequency_Transformer_Single('SDAYPair', 'Label')), \n",
    "        ('fq_USD', Frequency_Transformer_Single('USD_amount', 'Label')),\n",
    "        ('fq_ssector', Frequency_Transformer_Single('Sender_Sector', 'Label')),\n",
    "        ('fq_bene', Frequency_Transformer_Single('Bene_Account', 'Label'))\n",
    "        ])\n",
    "\n",
    "X_train = feature_pipeline.fit_transform(X_train_raw)\n",
    "X_test = feature_pipeline.transform(X_test_raw)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, \n",
    "                          n_jobs=-1,\n",
    "                          eta=0.1,\n",
    "                          max_depth=6,\n",
    "                          reg_alpha=1, # L1 regularization\n",
    "                          n_estimators=100)\n",
    "xgb_model = xgb_model.fit(X_train[features], y_train)\n",
    "\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0132fec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
